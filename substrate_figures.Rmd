---
title: "Comprehensive, coastwide marine substrate classification"
subtitle: "Tables and figures"
author: "Edward Gregr"
last revision: "2021/08/26"
output: word_document
---

See Plot.Obs.By.IDS.For.Regions for facet strip formatting stuff.   

Tables 1 and 2 (summaries of data sources) are not generated by this script. They need to be copied from the previous version of the relevant word doc. See the document assembly notes in the supporting tech document. 


```{r Build_Table3, echo=FALSE}
library( knitr )
knitr::opts_chunk$set(fig.width=12, fig.height=8) 

#-- Main statistics don't make a very nice bar plot. Report as table. 
T.cap <- "Table 3: Aggregated build metrics for all 6 models comparing the 384 weighted (first row) and the unweighted (second row) random forest results. Out of bag (OOB) values show the mean prediction error from the random forest internal cross-validation. The true skill statistic (TSS) corrects accuracy for chance and prevalence and measures how model
performance exceeds random. Overall accuracy, TNR, Quantity, Exchange and Shift provide an assessment of model error. See Supplementary materials S1 for details on the metrics." 

x <- rbind( build.sum$build.results.Integrated,
            build.sum.nw$build.results.Integrated )

# adjust region levels ... arguably should be much earlier ... 
# levels( x$Region ) <- fct_relevel(x$Region, "Coast", "HG", "NCC", "WCVI", "QCS", "SOG" )

x <- x[ order(x$Region),]
x <- x[ , c( 'Region', 'N', 'Imbalance', 'OOB', 'TSS', 'Accuracy', 'TNR', 'Quantity', 'Exchange', 'Shift')]
row.names(x) <- NULL

kable( x , digits=2, caption = T.cap )

```

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```

```{r Build_Table4, echo=FALSE}
library( knitr )
knitr::opts_chunk$set(fig.width=12, fig.height=8) 

# Table of IDE results. 
T.cap <- "Table 4: Performance of each random forest model against each independent data set." 

#- Build an IDE results table for the Wtd model ... 

x <- IDE.results.wtd$Integrated
y <- rbind( x[x$IDS=='Dive',], 
            x[x$IDS=='Cam',],
            x[x$IDS=='ROV',]
  )
z <- cbind( 'IDS'=y$IDS, y[,-2] )
rownames( z ) <- NULL

x <- z
x <- x[, !(names(x) %in% c("OOB")) ]
x <- x[ , c( 'IDS', 'Region', 'N', 'Imbalance', 'TSS', 'Accuracy', 'TNR', 'Quantity', 'Exchange', 'Shift')]
#names(x)[7] <- 'Specificity'
row.names( x ) <- NULL

kable( x, digits=2, caption = T.cap )

```   

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


**Figure 1 (External): Map of study area showing outline of the six models developed in this analysis.**

```{r Fig_2_Build_Heatmaps, echo=FALSE}

# As superheat library only writes  pngs, they have to be pre-built.
# NOTE multi-panel built from the heatmap output in PPT.

```
**Figure 2 (External): Heatmaps of model performance.**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


```{r Fig_3_Build_Prevalence, echo=FALSE }

#-- Prevalence plots (obs & predicted) for build (testing partition), faceted by Region
a <- build.sum$build.results.ClassPrev
b <- build.sum.nw$build.results.ClassPrev[7:12,]

#-- Added 2021/06/14 along with 'Rock' above to standarize all figures in ms. 
colnames(a) <- c('Stat','Region','Rock',"Mixed",'Sand',"Mud")
colnames(b) <- c('Stat','Region','Rock',"Mixed",'Sand',"Mud")

# change numbers to proportions
x <- a[, names(a) %in% c('Rock', 'Mixed', 'Sand', 'Mud')]
y <- data.frame(  x / rowSums( x ))

# add results back to the Region column
z <- cbind( 'Region' = a$Region, 'Source' = c(rep('Observed',6), rep('Weighted',6)), y)

#--- do it again with the non-wtd model, this time keep only the predictions ... 

x <- b[, names(b) %in% c('Rock', 'Mixed', 'Sand', 'Mud')]
y <- data.frame(  x / rowSums( x ))
zz <- cbind( 'Region' = b$Region, 'Source' = rep('No Weights',6), y)

foo <- rbind( z, zz)

a <- Plot.Obs.Pred.Prevalence.Build( foo, pal.cb3b, sz=30, lx=0.15, ly=0.85 ) 

ggsave( paste0( 'Figure 3 - Comparison of class prevalence.png'), a, dpi = 300, width = 16, height = 
10, path = results.dir)

a
```

**Figure 3: Comparison of class prevalence. Observed class prevalences in the build testing partition (orange) compared to predictions from the weighted (yellow) and unweighted (blue) random forest models across models.**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


**Figure 4: (External) Predictions in regional assessment areas.**


**Figure 5: (External) Heatmap of variable importance across models.**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


```{r Fig6a_Depth_Results_by_Resolution_TSS, echo=FALSE, fig.width=10, fig.height=6, out.width='100%'}


# This code  builds the data used by the panels in Fig 7.
z <- depth.results

# Build some difference columns, and add them back to z. NOTE they are half the length, but can just pull the top half of the list for plotting. 

dif <- z[ z$Model == '100 m', ]$TSS - z[ z$Model == '20 m', ]$TSS
z <- cbind( z, 'diffTSS' = dif )

dif <- z[ z$Model == '100 m', ]$TNR - z[ z$Model == '20 m', ]$TNR
z <- cbind( z, 'diffTNR' = dif )

#Plot.TSS.By.Depth.For.Regions(  z[ , c('Model', 'Region', 'Ribbon', 'TSS')], pal.cb2 )
y <- z[ 1:40, c('Model', 'Region', 'Ribbon', 'diffTSS')]
names(y)[4] <- 'diff'
a <- Plot.Stat.By.Depth.For.Regions( y, 'TSS', pal.cb2[2] )

ggsave( paste0( 'Figure 6a - Depth results.png'), a, dpi = 300, width = 15, height = 10, path = results.dir)

a

```
**Figure 6a: **  

```{r Fig6b_Depth_Results_by_Resolution_TNR, echo=FALSE, fig.width=10, fig.height=6, out.width='100%'}
y <- z[ 1:40, c('Model', 'Region', 'Ribbon', 'diffTNR')]
names(y)[4] <- 'diff'
a <- Plot.Stat.By.Depth.For.Regions( y, 'TNR', pal.cb2[2] )

ggsave( paste0( 'Figure 6b - Depth results.png'), a, dpi = 300, width = 15, height = 10, path = results.dir)

a

```
**Figure 6b: **  

**Figure 6: Differences in model fit by region, across depths and resolutions (2 panels).**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


```{r Fig7a_Depth_Results_Obs_Pontius, echo=FALSE, fig.width=10, fig.height=6, out.width='100%'}

z <- depth.results[ depth.results$Model == '100 m', ]

#Adjust accuracy so bars are all the same height 
z$Accuracy <- 1 - (z$Shift + z$Exchange + z$Quantity)

a <- Plot.Pontius.By.Depth.For.Regions( z, rev(pal.cb4) )
ggsave( paste0( 'Figure 7a - Error metrics by region.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a
```

**Figure 7a:**  

```{r Fig7b_Depth_Results_Obs_Pontius, echo=FALSE, fig.width=10, fig.height=6, out.width='100%'}

z <- depth.results[ depth.results$Model == '20 m', ]

#Adjust accuracy so bars are all the same height 
z$Accuracy <- 1 - (z$Shift + z$Exchange + z$Quantity)

a <- Plot.Pontius.By.Depth.For.Regions( z, rev(pal.cb4) )

ggsave( paste0( 'Figure 7b - Error metrics by region.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a
```

**Figure 7b: **

**Figure 7: Comparison of error metrics by region, depth and resolution (2 panels).**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```

**Figure 8: (External) Mapped predictions for different resolutions (2 panels).**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


```{r Fig9_IDS_One, echo=FALSE, out.width='120%', fig.fullwidth=TRUE}

# 3) Look at Integrated statistics for each IDS by Region.
# Use a predetermined collection of stats (see function)

# Again, start with a little data prep ... 

y <- IDE.results.wtd$Integrated
z <- y[ y$Region %in% c('Coast', 'HG', 'NCC'), ]

# This function can be used to generate various views of the data. 
# 2020/05/25 DH preferred IDS as the grouping variable ... 
# 2020/08/23 Standardized them all as the difference from random baseline
a <- Plot.Stats.By.IDS.For.Regions( y, pal.cb3b, sz = 25, lx=0.85, ly=0.87 )

ggsave( paste0( 'Figure 9 - Integrated Stats by IDE for Regions.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a

```

**Figure 9: Aggregated accuracy metrics of predictive power for each independent data set by region. **  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


```{r Fig10a_IDS_By_Ribbon_A, echo=FALSE, out.width='120%', fig.fullwidth=TRUE}
# Pontius stats (Accuracy, Quantity, Exchange, Shift) for IDS, by ribbon, 
# one plot for each region.
# Remember: Accuracy = 1 â€“ (Quantity + Exchange + Shift).

z <- IDE.depths[ IDE.depths$Region == 'Coast', c( 'IDS', 'Ribbon', 'Accuracy', 'Shift','Exchange','Quantity' )]

#Adjust accuracy so bars are all the same height 
z$Accuracy <- 1 - (z$Shift + z$Exchange + z$Quantity)

a <- Plot.Pontius.By.IDS.Depth.For.Regions( z, rev(pal.cb4), sz = 35 )

ggsave( paste0( 'Figure 10a - IDE Error metrics by depth.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a

```  

**Figure 10a: **  

```{r Fig10b_IDS_By_Ribbon_B, echo=FALSE, out.width='120%', fig.fullwidth=TRUE}
z <- IDE.depths[ IDE.depths$Region == 'HG', c( 'IDS', 'Ribbon', 'Accuracy', 'Shift','Exchange','Quantity' )]

#Adjust accuracy so bars are all the same height 
z$Accuracy <- 1 - (z$Shift + z$Exchange + z$Quantity)

a <- Plot.Pontius.By.IDS.Depth.For.Regions( z, rev(pal.cb4), sz = 35 )

ggsave( paste0( 'Figure 10b - IDE Error metrics by depth.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a
```  

**Figure 10b: **  

```{r Fig10c_IDS_By_Ribbon_C, echo=FALSE, out.width='120%', fig.fullwidth=TRUE}
z <- IDE.depths[ IDE.depths$Region == 'NCC', c( 'IDS', 'Ribbon', 'Accuracy', 'Shift','Exchange','Quantity' )]

#Adjust accuracy so bars are all the same height 
z$Accuracy <- 1 - (z$Shift + z$Exchange + z$Quantity)

a <- Plot.Pontius.By.IDS.Depth.For.Regions( z, rev(pal.cb4), sz = 35 )

ggsave( paste0( 'Figure 10c - IDE Error metrics by depth.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a
```  

**Figure 10c: **

**Figure 10: Error assessment of predictive power by depth zone (3 panels).**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


# Supplemental tables (6) and figures (2)
# Tables S1 thru S3 maintained externally.

```{r Supp_Tables, echo=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3) 

T.cap <- "Table S4: Error matrices for the six weighted models. Prevalence (Prev), User and Producer (Prod) accuracies are provided to interpret model fit (Predictions) to the build testing data (Reference)."  

x <- Error.Matrix( rf.region.Coast, obs.100mIV[ obs.100mIV$TestDat == 1, ] )
kable( x , digits=2, caption = T.cap )
cat('Coastwide')

x <- Error.Matrix( rf.region.HG,   obs.20mIV$HG[  obs.20mIV$HG$TestDat == 1, ] )
kable( x , digits=2 )
cat('HG')

x <- Error.Matrix( rf.region.NCC,   obs.20mIV$NCC[  obs.20mIV$NCC$TestDat == 1, ] )
kable( x , digits=2 )
cat('NCC')

x <- Error.Matrix( rf.region.WCVI,   obs.20mIV$WCVI[  obs.20mIV$WCVI$TestDat == 1, ] )
kable( x , digits=2 )
cat('WCVI')

x <- Error.Matrix( rf.region.QCS,   obs.20mIV$QCS[  obs.20mIV$QCS$TestDat == 1, ] )
kable( x , digits=2 )
cat('QCS')

x <- Error.Matrix( rf.region.SOG,   obs.20mIV$SOG[  obs.20mIV$SOG$TestDat == 1, ] )
kable( x , digits=2 )
cat('SOG')

```

**Figure S1 (External): Map of sample distribution.**  

```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


```{r FigS2_SampleSize_IDS, fig.width=10, fig.height=6, out.width='120%', echo=FALSE}
# Depends on IDE.results created in main script. 
#--- 1) Begin by looking at IDS sample sizes using perClass prevalences 
x <- IDE.results.wtd$PerClass
y <- x[ x$Stat == 'PrevObs', ]

# Tidy the data a bit  ... 
y <- x[ x$Stat == 'PrevObs', ] %>% subset(select = -c(Stat))
colnames(y) <- c( 'Region', 'IDS', 'Rock', 'Mixed', 'Sand', 'Mud')
rownames(y) <- NULL

# fill in  blank data to balance plot ... 
y <- rbind( y, data.frame( 'Region' = 'WCVI', 'IDS' = 'ROV', 'Rock'=0, 'Mixed'= 0, 'Sand'=0, 'Mud'=0),
               data.frame( 'Region' = 'QCS',  'IDS' = 'ROV', 'Rock'=0, 'Mixed'= 0, 'Sand'=0, 'Mud'=0),
               data.frame( 'Region' = 'SOG',  'IDS' = 'ROV', 'Rock'=0, 'Mixed'= 0, 'Sand'=0, 'Mud'=0) )

a <- Plot.Obs.By.IDS.For.Regions( y, pal.cb3b, sz = 25, lx=0.83, ly=0.75 )

ggsave( paste0( 'Figure S2 - IDE sample sizes.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a
```

**Figure S2. Samples size of independent data sets by substrate class, across regions.**


```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```


```{r FigS2_Prevalence_ObsPred, fig.width=10, fig.height=6, echo=FALSE, out.width='120%' }
#-- Plots the Study Area prevalence results. 
#   Requires the map.prev and build.sum data structure for some data prep. 

a <- Plot.Pred.Map.Prevalence( map.prev, build.sum, pal.RMSM, sz = 25)

ggsave( paste0( 'Figure S2 - Comparison of prevalence.png'), a, dpi = 300, width = 16, height = 10, path = results.dir)

a
```

**Figure S2: Comparison of prevalence in predictions between fitted model (Points) and study area (Map).**    


```{=openxml}
# Inserting a word page break ... 
<w:p>
  </w:pPr>
    <w:r>
      <w:br w:type="page"/>
    </w:r>
</w:p>
```
